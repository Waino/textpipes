% side inputs and outputs
    % files need to be opened, requires handing down conf, cli_args
        % don't want to do this in init: only when make is called
        F hand it down in __call__ / single_cell ?
            - single_cell has do do bookkeeping to only open it once
        F pre/post-make call ?
            - a lot of boilerplate
        F only in __call__, with handling in SingleCellComponent or PipeComponent ?
        % in Pipe
            % don't want to tie Component to Pipe
            % pass in a dict RF -> fobj into __call__
            % still need an (empty if not needed) pre/post-make call for saving models
        % parallel (using multiprocessing) SingleCellComponent prevents shared side outputs
% what if there is no main_output to drive the generator?
    % e.g. if you just want to train a truecaser from a corpus file, and don't need the lines for anything else
    % third type of Pipe? DeadEndPipe
    % make a TrainTruecaserRule that uses DeadEndPipe, for convenience?

% slurm params from platform conf
% local platform

- tokenizer and truecaser have some rough edges

½ Concatenate(Rule)
½ multiple inputs when e.g. training truecaser (no need to concatenate first)
    % MonoPipe subclass that reads multiple inputs concatenated?
    % subclass hierarchy would clash with DeadEndPipe
        % otoh this training is exactly the usecase for both, so maybe combine?

- loop Rule that produces numbered outputs
    % early saves should be available to evaluate before run has finished
        - need to separate two types of file
            - atomic: e.g. model pickles
                - if the file exists, it can be assumed to be done
            - non-atomic: pipeline output, built up over time
                - file is not done while the job making it is still running
    % do we need a special RecipeFile with section:key:loop ?
        % pro
            - recipe DAG traversal is on RF level, cannot differentiate by cli_args
            - abuse of cli_args might cause bugs in future
        - neutral
            - sec_key given to platform.schedule, which uses it for --make (but cli_args also included there)
        - con
            - would need an extra class
            - would need non-encapsulated special handling (e.g. recipe._rf)
    - how are the evals scheduled?
        - if it is delayed by dep on train loop, it waits for too long
            - require extra flag to schedule with dep on atomic? --force-dep
        - if evals are in a separate recipe DAG, you'll get missing input errors
            - soft input that won't cause missing_inputs?
    - continuing from last
        - helper to find highest numbered file
    - only show one line in human-friendly output

- tooling for parameter grid search
    - conf has current best params
    - a grid search recipe has the ranges of possible values
    - helper combines the two into a subgrid
        - previously tried values will be done already, so no special handling needed
    - this is not so simple for random search

- cli usability issues
    % (at least local) platform should show process indicator
    ½ dryrun output is in random order
    % (non)recursive scheduling: flag
    % --check should check that gitdir is valid
    - waiting and running shows all outputs of a job on individual lines
    - default monitoring picks asciibetically first output
    - --status is failing to output useful stuff
        - (e.g. failed local jobs)
            - --dryrun also not showing it as running/failed
            - missing job_id is probably the problem
            - --status should also show available jobs, not just --dryrun ?
        - how long something has been running
        - estimated start time for scheduled
            - parsing "slurm q"
            - the current job-meta namedtuples (plus a dict for mutable status) are too rigid
        - rename waiting -> pending to equal slurm

- recipe usability issues
    - lots of boilerplate in preprocssing recipe
        - helpers for creating parallel processing paths for multiple corpora

- cli_args
- use package resources instead of data in source tree
- appended side outputs for e.g. anomaly logging
    - should be ignored in DAG

- speed
    % use multiprocessing.Pool.imap

- better line number guess
    - do wc on inputs, keep track of lines written into outputs using log
